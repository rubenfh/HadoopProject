{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Spark Session Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('log_reg').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " df=spark.read.csv('./Data/Log_Reg_dataset.csv',inferSchema=True,\n",
    "header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n"
     ]
    }
   ],
   "source": [
    "#The shape of the dataset \n",
    "print((df.count(), len(df.columns)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Repeat_Visitor: integer (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Web_pages_viewed: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the datatypes \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+--------------+--------+----------------+------+\n",
      "|  Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|\n",
      "+---------+---+--------------+--------+----------------+------+\n",
      "|    India| 41|             1|   Yahoo|              21|     1|\n",
      "|   Brazil| 28|             1|   Yahoo|               5|     0|\n",
      "|   Brazil| 40|             0|  Google|               3|     0|\n",
      "|Indonesia| 31|             1|    Bing|              15|     1|\n",
      "| Malaysia| 32|             0|  Google|              15|     1|\n",
      "|   Brazil| 32|             0|  Google|               3|     0|\n",
      "|   Brazil| 32|             0|  Google|               6|     0|\n",
      "|Indonesia| 27|             0|  Google|               9|     0|\n",
      "|Indonesia| 32|             0|   Yahoo|               2|     0|\n",
      "|Indonesia| 31|             1|    Bing|              16|     1|\n",
      "+---------+---+--------------+--------+----------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "|summary| Country|              Age|   Repeat_Visitor|Platform| Web_pages_viewed|            Status|\n",
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "|  count|   20000|            20000|            20000|   20000|            20000|             20000|\n",
      "|   mean|    null|         28.53955|           0.5029|    null|           9.5533|               0.5|\n",
      "| stddev|    null|7.888912950773227|0.500004090187782|    null|6.073903499824976|0.5000125004687693|\n",
      "|    min|  Brazil|               17|                0|    Bing|                1|                 0|\n",
      "|    max|Malaysia|              111|                1|   Yahoo|               29|                 1|\n",
      "+-------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# statistical measures \n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "| Malaysia| 1218|\n",
      "|    India| 4018|\n",
      "|Indonesia|12178|\n",
      "|   Brazil| 2586|\n",
      "+---------+-----+\n",
      "\n",
      "+--------+-----+\n",
      "|Platform|count|\n",
      "+--------+-----+\n",
      "|   Yahoo| 9859|\n",
      "|    Bing| 4360|\n",
      "|  Google| 5781|\n",
      "+--------+-----+\n",
      "\n",
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1|10000|\n",
      "|     0|10000|\n",
      "+------+-----+\n",
      "\n",
      "+--------+------------------+-------------------+---------------------+------------------+\n",
      "|Platform|          avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|       avg(Status)|\n",
      "+--------+------------------+-------------------+---------------------+------------------+\n",
      "|   Yahoo|28.569226087838523| 0.5094837204584644|    9.599655137437875|0.5071508266558474|\n",
      "|    Bing| 28.68394495412844| 0.4720183486238532|    9.114908256880733|0.4559633027522936|\n",
      "|  Google|28.380038055699707| 0.5149628092025601|    9.804878048780488|0.5210171250648676|\n",
      "+--------+------------------+-------------------+---------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply some filters \n",
    "df.groupBy('Country').count().show()\n",
    "df.groupBy('Platform').count().show()\n",
    "df.groupBy('Status').count().show()\n",
    "df.groupBy('Platform').mean().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------+--------+----------------+------+------------+\n",
      "|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_Num|\n",
      "+-------+---+--------------+--------+----------------+------+------------+\n",
      "|India  |41 |1             |Yahoo   |21              |1     |0.0         |\n",
      "|Brazil |28 |1             |Yahoo   |5               |0     |0.0         |\n",
      "|Brazil |40 |0             |Google  |3               |0     |1.0         |\n",
      "+-------+---+--------------+--------+----------------+------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical variable into numerical form and create a single vector combining all the input features\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "#Platform and country are string so we have to convert them \n",
    "Platform_indexer =StringIndexer(inputCol=\"Platform\", outputCol=\"Platform_Num\").fit(df)\n",
    "df = Platform_indexer.transform(df)\n",
    "df.show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# represent the values into a 1 vector \n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "Platform_encoder=OneHotEncoder(inputCol=\"Platform_Num\", outputCol=\"Platform_Vector\")\n",
    "Platform_encoder.setDropLast(False)\n",
    "ohe = Platform_encoder.fit(df)\n",
    "df = ohe.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Platform_Num|Platform_Vector|\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "|India  |41 |1             |Yahoo   |21              |1     |0.0         |(3,[0],[1.0])  |\n",
      "|Brazil |28 |1             |Yahoo   |5               |0     |0.0         |(3,[0],[1.0])  |\n",
      "|Brazil |40 |0             |Google  |3               |0     |1.0         |(3,[1],[1.0])  |\n",
      "+-------+---+--------------+--------+----------------+------+------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3,False)\n",
    "# (3,[0],[1.0]) represents a vector of lenght 3 :\n",
    "#   Size of vector : 3 \n",
    "#   Value contained : [1.0]\n",
    "#   position of 1.0 in vector [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_indexer = StringIndexer(inputCol=\"Country\",outputCol=\"Country_Num\").fit(df)\n",
    "df = country_indexer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Country  |count|\n",
      "+---------+-----+\n",
      "|Indonesia|12178|\n",
      "|India    |4018 |\n",
      "|Brazil   |2586 |\n",
      "|Malaysia |1218 |\n",
      "+---------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "|Country_Num|count|\n",
      "+-----------+-----+\n",
      "|0.0        |12178|\n",
      "|1.0        |4018 |\n",
      "|2.0        |2586 |\n",
      "|3.0        |1218 |\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country').count().orderBy('count',ascending=False).show(5,False)\n",
    "df.groupBy('Country_Num').count().orderBy('count',ascending=False).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+\n",
      "|Country|Country_Num|Country_Vector|\n",
      "+-------+-----------+--------------+\n",
      "|India  |1.0        |(4,[1],[1.0]) |\n",
      "|Brazil |2.0        |(4,[2],[1.0]) |\n",
      "|Brazil |2.0        |(4,[2],[1.0]) |\n",
      "+-------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_encoder = OneHotEncoder(inputCol=\"Country_Num\",outputCol=\"Country_Vector\")\n",
    "country_encoder.setDropLast(False)\n",
    "ohe = country_encoder.fit(df)\n",
    "df = ohe.transform(df)\n",
    "df.select(['Country','Country_Num','Country_Vector']).show(3,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Country_Vector|count|\n",
      "+--------------+-----+\n",
      "|(4,[0],[1.0]) |12178|\n",
      "|(4,[1],[1.0]) |4018 |\n",
      "|(4,[2],[1.0]) |2586 |\n",
      "|(4,[3],[1.0]) |1218 |\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Country_Vector').count().orderBy('count',ascending=False).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the culumns that we need to to usse to create the vector \n",
    "df_assembler = VectorAssembler(inputCols=['Platform_Vector','Country_Vector','Age', 'Repeat_Visitor','Web_pages_viewed'], outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Repeat_Visitor: integer (nullable = true)\n",
      " |-- Platform: string (nullable = true)\n",
      " |-- Web_pages_viewed: integer (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- Platform_Num: double (nullable = false)\n",
      " |-- Platform_Vector: vector (nullable = true)\n",
      " |-- Country_Num: double (nullable = false)\n",
      " |-- Country_Vector: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+------+\n",
      "|features                                |Status|\n",
      "+----------------------------------------+------+\n",
      "|(10,[0,4,7,8,9],[1.0,1.0,41.0,1.0,21.0])|1     |\n",
      "|(10,[0,5,7,8,9],[1.0,1.0,28.0,1.0,5.0]) |0     |\n",
      "|(10,[1,5,7,9],[1.0,1.0,40.0,3.0])       |0     |\n",
      "|(10,[2,3,7,8,9],[1.0,1.0,31.0,1.0,15.0])|1     |\n",
      "|(10,[1,6,7,9],[1.0,1.0,32.0,15.0])      |1     |\n",
      "|(10,[1,5,7,9],[1.0,1.0,32.0,3.0])       |0     |\n",
      "|(10,[1,5,7,9],[1.0,1.0,32.0,6.0])       |0     |\n",
      "|(10,[1,3,7,9],[1.0,1.0,27.0,9.0])       |0     |\n",
      "|(10,[0,3,7,9],[1.0,1.0,32.0,2.0])       |0     |\n",
      "|(10,[2,3,7,8,9],[1.0,1.0,31.0,1.0,16.0])|1     |\n",
      "+----------------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " df.select(['features','Status']).show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " model_df=df.select(['features','Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14895\n"
     ]
    }
   ],
   "source": [
    "training_df,test_df=model_df.randomSplit([0.75,0.25])\n",
    "print(training_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1| 7457|\n",
      "|     0| 7438|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " training_df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5105\n"
     ]
    }
   ],
   "source": [
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Status|count|\n",
      "+------+-----+\n",
      "|     1| 2543|\n",
      "|     0| 2562|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    " test_df.groupBy('Status').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression(labelCol='Status').fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results=log_reg.evaluate(training_df).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------------------------------------+\n",
      "|Status|prediction|probability                             |\n",
      "+------+----------+----------------------------------------+\n",
      "|1     |1.0       |[0.2540780514504137,0.7459219485495864] |\n",
      "|1     |1.0       |[0.13802880928765998,0.8619711907123401]|\n",
      "|1     |1.0       |[0.07000976293178146,0.9299902370682186]|\n",
      "|1     |1.0       |[0.07000976293178146,0.9299902370682186]|\n",
      "|1     |1.0       |[0.07000976293178146,0.9299902370682186]|\n",
      "|1     |1.0       |[0.07000976293178146,0.9299902370682186]|\n",
      "|1     |1.0       |[0.07000976293178146,0.9299902370682186]|\n",
      "|1     |1.0       |[0.03418057622497152,0.9658194237750285]|\n",
      "|1     |1.0       |[0.03418057622497152,0.9658194237750285]|\n",
      "|1     |1.0       |[0.03418057622497152,0.9658194237750285]|\n",
      "+------+----------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results.filter(train_results['Status']==1).filter(train_results['prediction']==1).select(['Status','prediction','probability']).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- Status: integer (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results=log_reg.evaluate(test_df).predictions\n",
    "results.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Status|prediction|\n",
      "+------+----------+\n",
      "|0     |0.0       |\n",
      "|0     |0.0       |\n",
      "|0     |0.0       |\n",
      "|1     |0.0       |\n",
      "|1     |1.0       |\n",
      "|1     |1.0       |\n",
      "|1     |1.0       |\n",
      "|1     |1.0       |\n",
      "|1     |1.0       |\n",
      "|1     |1.0       |\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " results.select(['Status','prediction']).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = results[(results.Status == 1) & (results.prediction== 1)].count()\n",
    "tn = results[(results.Status == 0) & (results.prediction== 0)].count()\n",
    "fp = results[(results.Status == 0) & (results.prediction== 1)].count()\n",
    "fn = results[(results.Status == 1) & (results.prediction== 0)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2377\n",
      "2400\n",
      "162\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "print(tp)\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=float((true_postives+true_negatives) /(results.count()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
